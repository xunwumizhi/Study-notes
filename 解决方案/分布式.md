# 分布式理论、名词

## 分布式性能指标：CAP

- C - Consistency

数据一致。

- A - Availability

服务可用。可用性是指任何事务操作都可以得到响应结果，且不会出现响应超时或响应错误。服务可用

- P - Partition tolerance

网络分区容错。网络隔离下，部分节点可用

## base：满足 AP

基本可用(Basically Available）、软状态(Soft State)、最终一致性(Eventual Consistency)—— 缩写为 Base



## 一致性探讨

一致性的分级程度：

- 线性一致性Linearizability consistency ，也叫原子性。       Raft
- 顺序一致性 Sequential consistency：							        ZooKeeper
- 因果一致性 Causal consistency
- 最终一致性 Eventual consistency



理论的工程实现

Raft：etcd

Paxos: ZK

# 分布式事务

## 2PC 两阶段提交 2 phase - prepare commit

分为 prepare 阶段和 commit 阶段。分布式事务处理模型 DTP（Distributed Transaction Processing Reference Model）其中定义了对应角色：

AP（app program）:应用程序
RM（Resource Manager）：资源管理器，事务的参与方
TM（Transaction Manager）：事务管理器

### 2pc 之 XA 方案

DTP 定义 TM RM 之间接口规范有 XA。TM 通过 XA 接口来通知 RM 进行准备、提交、回滚

基于XA 接口实现2pc方案，称为XA方案。

1）在准备阶段RM执行实际的业务操作，但不提交事务，资源锁定；

2）在提交阶段TM会接受RM在准备阶段的执行回复，只要有任一个RM执行失败，TM会通知所有RM执行回滚操 作，否则，TM将会通知所有RM提交该事务。提交阶段结束资源锁释放。

因此有如下缺点：

1、需要本地数据库支持XA协议。

2、资源锁需要等到两个阶段结束才释放，性能较差。

### 2pc 之 Seata

全局事务划分为多个分支事务，与XA不同，seata 定义了3个组件

TM，RM，TC（transaction coordinator）

Transaction Manager (TM)：事务管理器，TM需要嵌入应用程序中工作，它负责开启一个全局事务，并最终 向TC发起全局提交或全局回滚的指令。

Transaction Coordinator (TC)：事务协调器，它是独立的中间件，需要独立部署运行，它维护全局事务的运 行状态，接收TM指令发起全局事务的提交与回滚，负责与RM通信协调各各分支事务的提交或回滚。

交互流程变成

TM <-开启全局事务/提交/回滚-> TC 

TC <-分支提交/回滚-> RM1

TC <-分支提交/回滚-> RM2

### XA 与 Seata 对比

架构层次方面，传统2PC方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身，通过 XA 协议实现，而 Seata的 RM 是以jar包的形式作为中间件层部署在应用程序这一侧的。

两阶段提交方面，传统2PC无论第二阶段的决议是commit还是rollback，事务性资源的锁都要保持到Phase2完成 才释放。而Seata的做法是在Phase1 就将本地事务提交，这样就可以省去Phase2持锁的时间，整体提高效率。

## TCC 事务 

TCC是Try、Confirm、Cancel三个词语的缩写，TCC要求每个分支事务实现三个操作：

- 预处理Try：

Try 阶段是做业务检查(一致性)及资源预留(隔离)，此阶段仅是一个初步操作，它和后续的Confirm 一起才能 真正构成一个完整的业务逻辑。

- 确认 Confirm

Confirm 阶段是做确认提交，Try阶段所有分支事务执行成功后开始执行 Confirm。通常情况下，采用TCC则 认为 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。若Confirm阶段真的出错了，需引 入重试机制或人工处理。

- 撤销Cancel

Cancel 阶段是在业务执行错误需要回滚的状态下执行分支事务的业务取消，预留资源释放。通常情况下，采 用TCC则认为Cancel阶段也是一定成功的。若Cancel阶段真的出错了，需引入重试机制或人工处理。

空释放：如果try请求丢失，cancel释放没有被锁住的资源；因此业务；

流程乱序：try 超时失败，cancel 执行，结果try随后又达到了，这时要注意判断 唯一事务ID 的状态 

一个简化例子
```
# 账户A
    try：
        try幂等校验 
        try悬挂处理 
        检查余额是否够30元 
        扣减30元 
    confirm：
        空 
    cancel：
        cancel幂等校验 
        cancel空回滚处理 
        增加可用余额30元

# 账户B
    try：
        空 
    confirm：
        confirm幂等校验 
        正式增加30元 
    cancel：
        空   
```

## 2PC 与 TCC

如果拿TCC事务的处理流程与2PC两阶段提交做比较，2PC通常都是在跨库的DB层面，而TCC则在应用层面的处 理，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，可以让应用自己定义数据操作的粒度，使 得降低锁冲突、提高吞吐量成为可能。

而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此 外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。

## 本地消息表与 MQ 事务消息

### 本地消息表

本地消息表和业务数据处于同个DB中，利用DB事务保证两者同时更新；

本地事务业务进程
```
begin transaction；
    //1.新增用户 
    //2.存储积分消息日志 
commit transation;
```

本地另一进程扫日志重试后续操作。

因此本地事务不提供回滚

### RocketMQ 事务消息

对本地消息表的封装。将本地消息表移动到了 MQ 内部。

1. producer half消息 -> MQ
2. producer 本地事务
3. producer <- 本地事务执行结果commit/rollback -> MQ
3.1 在3通信失败情况下，MQ <-查询本地事务状态-> producer
4. 根据3结果，MQ选择 commit 向consumer投递消息/ rollback MQ删除本地消息
4.1 投递失败，调用 producer 回滚接口

## 不回滚的最大努力通知

事务一方来轮询状态

## 方案对比

```
        2PC	      TCC	    可靠消息   最大努力通知
一致性	 强一致性	最终一致	最终一致	最终一致
吞吐量	   低	     中	        高	       高
实现复杂度	易	      难	     中	        易
```

![图片](./test.drawio.png)


# 分布式事务框架

DBPack 文档: https://cectc.github.io/dbpack-doc/#/blogs/eda-design


# 分布式缓存

读 Redis 配置每个进程本地缓存一份，Redis 更新后，所有节点是否要同时更新

Redis 缓存和 Mysql 同步
